# 大模型自动标注实验报告

## 1. 任务概述

本实验旨在展示如何利用基础大模型（Foundation Models）对非结构化文本数据进行自动标注（Auto-Labeling）。
我们选择了 **情感分析（Sentiment Analysis）** 作为演示任务，目标是将中文评论文本分类为 `positive`（正面）或 `negative`（负面）。

### 1.1 数据集选择
- **数据集名称**: `lansinuote/ChnSentiCorp`
- **来源**: 本地文件 (`data/0000.parquet`)，源自 Hugging Face。
- **描述**: 这是一个广泛使用的中文情感分析数据集，包含酒店、书籍、电子产品等多个领域的评论。
- **数据量**: 实验中从本地 9600 条数据中随机抽取了 10 条样本进行演示。

### 1.2 模型选择
- **模型**: Qwen-Turbo (通义千问)
- **调用方式**: 通过阿里云 DashScope API (OpenAI 兼容接口)
- **选择理由**: 中文理解能力强，API 响应速度快，成本低。

## 2. 方法论

### 2.1 Prompt 工程设计
为了确保模型输出结果可被程序解析，我们采用了 **结构化 Prompt** 设计。

**System Prompt 核心策略**:
1.  **角色设定**: "你是一位资深的情感分析专家。"
2.  **明确任务**: 分析文本情感倾向。
3.  **强制格式**: 要求必须输出合法的 JSON 格式。
4.  **字段定义**:
    - `label`: "positive" 或 "negative"
    - `confidence`: 0.0 - 1.0 的置信度
    - `reasoning`: 简要的中文理由说明

### 2.2 自动标注流程
1.  **数据加载**: 
    - 直接读取本地 Parquet 格式数据集文件 (`data/0000.parquet`)。
    - 使用 Pandas 的 `read_parquet` 接口处理数据。
2.  **API 配置**:
    - 针对国内网络环境或特定代理设置，使用了 `httpx.Client(trust_env=False)` 来强制绕过系统代理，确保 Python 脚本能直连阿里云 API。
3.  **批量推理**: 遍历数据，构建 Prompt，调用 LLM API。
4.  **错误处理**: 
    - 包含 API 连接重试机制 (Retries)。
    - 包含 JSON 解析异常处理 (JSONDecodeError)。
5.  **结果存储**: 将原始文本、真实标签、模型预测标签、置信度和理由保存为 CSV 文件。

## 3. 实验结果分析

### 3.1 准确率评估
在本次运行的随机样本中，模型在大多数情况下表现优异，但在处理复杂语义时展现出了一些局限性。
- **简单样本**: 对于“服务不错”、“盖子盖不严实”等直白的评论，准确率 100%。
- **复杂样本**: 涉及深层语义理解或反讽时，模型可能产生误判。

### 3.2 典型案例分析 (基于真实运行结果)

#### 案例 1: 正面评价 (准确识别)
- **文本**: "商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!"
- **真实标签**: 1 (Positive)
- **模型预测**: `positive` (置信度 0.95)
- **理由**: "文本中使用了‘房间很大’、‘床有2M宽’和‘经济实惠不错’等正面描述，表达了对商务大床房的满意和认可。"
- **分析**: 模型准确捕捉到了关键词。

#### 案例 2: 负面评价 (准确识别)
- **文本**: "盖子盖不严实，有缝隙，按上去还带响... 显卡切换的时候有短暂的黑屏现象！"
- **真实标签**: 0 (Negative)
- **模型预测**: `negative` (置信度 0.95)
- **理由**: "文本中提到产品存在多个问题... 这些描述均表现出对产品质量的不满。"
- **分析**: 模型能从长文本中提取多个负面特征。

#### 案例 3: 复杂语义/错判案例 (值得深思)
- **文本**: "我想，如果我们想分辨人间的正义... 极端的民族主义，叫嚣的正义，会给这个世界毁灭性的打击... 所以，拒绝战争，珍惜和平"
- **真实标签**: 1 (Positive - 对这本反战书籍的认可)
- **模型预测**: `negative`
- **理由**: "文本表达了对战争的强烈反对和对极端民族主义的批判，提到战争带来的悲剧... 整体情感倾向为负面。"
- **分析**: 这是一个典型的**情感对象错位**。
    - **用户意图**: 通过批判战争来赞美这本书（书是好的）。
    - **模型视角**: 文本中充满了“战争”、“悲剧”、“毁灭性”等负面词汇，且表达了沉重的情绪。
    - **启示**: 在 Prompt 中可能需要更明确地指示模型关注“用户对商品/作品的态度”而非“文本内容本身描述的事件的性质”。

## 4. 思考：人工标注 vs AI 标注

| 维度 | 人工标注 (Human Labeling) | AI 自动标注 (LLM Labeling) |
| :--- | :--- | :--- |
| **速度** | 慢 (秒级/条) | 极快 (并发可达数千条/秒) |
| **成本** | 高 (需要人力培训和薪资) | 低 (API 调用成本极低) |
| **一致性** | 易受主观疲劳影响 | 高 (相同 Temperature 下输出稳定) |
| **理解力** | 极高 (懂反讽、文化梗) | 高 (但对极其隐晦的表达可能误判，如案例3) |

## 5. 改进建议

1.  **优化 Prompt**:
    针对书籍或电影评论，明确指示模型：“请评估用户对**该作品**的评价是正面还是负面，即使作品内容本身涉及悲剧或战争。”
    
2.  **Human-in-the-loop (人机回环)**:
    设置置信度阈值。对于高置信度样本直接采纳，低置信度样本转交给人工审核。这样可以在保证质量的同时最大化效率。
